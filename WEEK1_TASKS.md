# ğŸ¯ æ·±åº¦å­¦ä¹ ç¬¬ä¸€å‘¨ä»»åŠ¡ï¼šPromptå·¥ç¨‹æŒæ¡

## Week 1, Day 1-2: ReActèŒƒå¼æ·±åº¦ç†è§£

### å­¦ä¹ ç›®æ ‡
ç†è§£ä¸ºä»€ä¹ˆReActè¿™æ ·è®¾è®¡ï¼Œå®ƒè§£å†³äº†ä»€ä¹ˆé—®é¢˜

### ğŸ“š èƒŒæ™¯çŸ¥è¯†

**é—®é¢˜èƒŒæ™¯**ï¼š
ä¼ ç»ŸLLMä¸€æ¬¡æ€§ç»™å‡ºç­”æ¡ˆï¼Œå®¹æ˜“å‡ºé”™ï¼Œä¸”æ— æ³•è¿½è¸ªæ¨ç†è¿‡ç¨‹ã€‚

**ReActçš„è§£å†³æ–¹æ¡ˆ**ï¼š
å¼ºåˆ¶æ¨¡å‹æŒ‰ç…§ Thought â†’ Action â†’ Observation çš„å¾ªç¯ï¼Œæ¯æ­¥éƒ½å¯éªŒè¯

### ğŸ” æ·±åº¦åˆ†æ

åˆ›å»ºæ–‡ä»¶ï¼š`week1_react_analysis.md`

```markdown
# ReActèŒƒå¼æ·±åº¦åˆ†æ

## ä¸ºä»€ä¹ˆThoughtå¾ˆå…³é”®ï¼Ÿ

### æ²¡æœ‰Thoughtçš„Agent
è¾“å…¥: "è®¡ç®— (5+3)*2"
ç›´æ¥è¾“å‡º: "16"

é—®é¢˜:
- ä¸çŸ¥é“Agentæ˜¯æ€æ ·æ€è€ƒçš„
- å¦‚æœé”™è¯¯ï¼Œæ— æ³•å®šä½é—®é¢˜
- éš¾ä»¥éªŒè¯é€»è¾‘

### æœ‰Thoughtçš„Agent
Thought: è¿™ä¸ªè¡¨è¾¾å¼éœ€è¦å…ˆç®—æ‹¬å·ï¼Œå†ç®—ä¹˜æ³•
- æŒ‰ç…§æ•°å­¦è§„åˆ™ï¼Œ5+3=8
- ç„¶å 8*2=16

ä¼˜åŠ¿:
- æ¨ç†è¿‡ç¨‹å¯è§
- å¦‚æœé”™äº†ï¼Œèƒ½æ‰¾åˆ°é”™è¯¯çš„åœ°æ–¹
- èƒ½è¯„ä¼°é€»è¾‘æ˜¯å¦æ­£ç¡®

## ä¸ºä»€ä¹ˆActionå’ŒObservationæˆå¯¹å‡ºç°ï¼Ÿ

### ç›®çš„: å®ç°åé¦ˆå¾ªç¯

Action (è¡ŒåŠ¨) â†’ Observation (è§‚å¯Ÿç»“æœ) â†’ Thought (æ–°æ€è€ƒ)

ä¾‹å¦‚:
```
Thought: æˆ‘éœ€è¦å…ˆæŸ¥è¯¢ä»€ä¹ˆæ˜¯RAG
Action: æœç´¢ "RAGå®šä¹‰"
Observation: å¾—åˆ°"æ£€ç´¢å¢å¼ºç”Ÿæˆ..."çš„å®šä¹‰
Thought: å¥½çš„ï¼Œç°åœ¨æˆ‘ç†è§£äº†ã€‚ç»§ç»­ä¸‹ä¸€ä¸ªä»»åŠ¡
Action: ...
```

## ä¸ºä»€ä¹ˆè¦æœ‰å¤šä¸ªå¾ªç¯ï¼Ÿ

### å¤æ‚ä»»åŠ¡éœ€è¦å¤šæ­¥éª¤

å¯¹äºç®€å•é—®é¢˜: 1ä¸ªå¾ªç¯å¤Ÿäº†
```
Thought: ç›´æ¥èƒ½å›ç­”
Action: æä¾›ç­”æ¡ˆ
```

å¯¹äºå¤æ‚é—®é¢˜: å¤šä¸ªå¾ªç¯
```
Thought: éœ€è¦æ›´å¤šä¿¡æ¯
Action: æœç´¢ä¿¡æ¯
Observation: å¾—åˆ°ä¿¡æ¯
Thought: ç°åœ¨èƒ½åˆ†æäº†
Action: åˆ†æ
Observation: å¾—åˆ°ç»“æœ
Thought: æœ‰æ–°é—®é¢˜
Action: ...
```

## ReActå¦‚ä½•æé«˜å‡†ç¡®æ€§ï¼Ÿ

### å‡†ç¡®æ€§æ¥è‡ªäº:
1. **å¯è§çš„æ¨ç†**: é”™è¯¯å®¹æ˜“è¢«å‘ç°
2. **åé¦ˆå¾ªç¯**: å¯ä»¥è‡ªæˆ‘çº æ­£
3. **å¼ºåˆ¶æ€è€ƒ**: é˜²æ­¢å†²åŠ¨å†³ç­–
4. **éªŒè¯æœºåˆ¶**: æ¯æ­¥éƒ½èƒ½æ£€æŸ¥

### æ•°æ®æ”¯æŒ:
- æ²¡æœ‰ReAct: å‡†ç¡®ç‡ 62%
- æœ‰ReAct: å‡†ç¡®ç‡ 86%
- æå‡: 24%

## ä½•æ—¶é€‰æ‹©ReActï¼Ÿ

### âœ… é€‚åˆ:
- å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡
- éœ€è¦ä½¿ç”¨å·¥å…·çš„ä»»åŠ¡
- éœ€è¦æ¨ç†çš„ä»»åŠ¡
- ç­”æ¡ˆéœ€è¦éªŒè¯çš„ä»»åŠ¡

### âŒ ä¸é€‚åˆ:
- ç®€å•äº‹å®æŸ¥è¯¢
- ç›´æ¥ç”Ÿæˆå†…å®¹
- éœ€è¦åˆ›æ„çš„ä»»åŠ¡
- ä½å»¶è¿Ÿè¦æ±‚

## ReActçš„å˜ä½“å’Œæ”¹è¿›

### ReAct-Code
åŠ å…¥ä»£ç æ‰§è¡Œåé¦ˆ:
```
Action: æ‰§è¡ŒPythonä»£ç 
Code: result = sum([1,2,3,4,5])
Observation: result = 15
```

### Self-Ask-With-Search
åŠ å…¥"è¿™ä¸ªé—®é¢˜æˆ‘éœ€è¦æœç´¢"çš„åˆ¤æ–­:
```
Thought: æˆ‘éœ€è¦æœç´¢"Pythonçš„æœ€æ–°ç‰ˆæœ¬"å—?
Answer: æ˜¯çš„ï¼Œå› ä¸ºè¿™æ˜¯å®æ—¶ä¿¡æ¯
Search: ...
```

### Reflexion
åŠ å…¥åæ€ç¯èŠ‚:
```
[æ‰§è¡Œæ­¥éª¤]
Reflection: æˆ‘åšçš„å¯¹ä¸å¯¹?
Self-Critique: é€»è¾‘æœ‰é—®é¢˜ï¼Œåº”è¯¥...
Revised Plan: ...
```
```

### å®éªŒä»»åŠ¡

åˆ›å»ºæ–‡ä»¶ï¼š`week1_react_experiment.py`

```python
# ReActå®éªŒï¼šå¯¹æ¯”æœ‰æ— Thoughtçš„æ•ˆæœ

class ReactExperiment:
    """ReActèŒƒå¼å®éªŒ"""
    
    def __init__(self):
        self.results = []
    
    def experiment_without_thought(self, task: str) -> str:
        """ä¸æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„Agent"""
        # æ¨¡æ‹ŸLLMç›´æ¥ç»™å‡ºç­”æ¡ˆ
        if "5+3" in task:
            return "8"
        elif "æ€»å’Œ" in task:
            return "15"  # å¯èƒ½é”™è¯¯
        return "ä¸çŸ¥é“"
    
    def experiment_with_thought(self, task: str) -> str:
        """æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹çš„Agent (ReAct)"""
        response = ""
        
        if "5+3" in task:
            response = """
Thought: ç”¨æˆ·è¦æ±‚è®¡ç®—5+3ï¼Œè¿™æ˜¯ç®€å•çš„åŠ æ³•
Action: ä½¿ç”¨è®¡ç®—å™¨
Action Input: 5+3
Observation: 8
Final Answer: 5+3çš„ç»“æœæ˜¯8
"""
        elif "æ€»å’Œ" in task:
            response = """
Thought: ç”¨æˆ·è¦æ±‚1åˆ°5çš„æ€»å’Œï¼Œæˆ‘éœ€è¦é€ä¸ªç›¸åŠ 
Action: åˆ†æ­¥è®¡ç®—
- 1+2=3
- 3+3=6
- 6+4=10
- 10+5=15
Final Answer: 1åˆ°5çš„æ€»å’Œæ˜¯15
"""
        
        return response
    
    def compare_results(self):
        """å¯¹æ¯”ä¸¤ç§æ–¹å¼çš„æ•ˆæœ"""
        tasks = [
            "è®¡ç®—5+3",
            "è®¡ç®—1åˆ°5çš„æ€»å’Œ",
            "è®¡ç®—(100-50)*2"
        ]
        
        results = {
            "without_thought": [],
            "with_thought": []
        }
        
        for task in tasks:
            # æ–¹å¼1ï¼šä¸æ˜¾ç¤ºæ€è€ƒ
            r1 = self.experiment_without_thought(task)
            results["without_thought"].append({
                "task": task,
                "response": r1,
                "verifiable": False  # æ— æ³•éªŒè¯
            })
            
            # æ–¹å¼2ï¼šæ˜¾ç¤ºæ€è€ƒï¼ˆReActï¼‰
            r2 = self.experiment_with_thought(task)
            results["with_thought"].append({
                "task": task,
                "response": r2,
                "verifiable": True  # å¯ä»¥éªŒè¯
            })
        
        return results
    
    def print_analysis(self, results):
        """æ‰“å°åˆ†æ"""
        print("\n" + "="*60)
        print("ReActèŒƒå¼æ•ˆæœå¯¹æ¯”")
        print("="*60)
        
        print("\nã€ä¸æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‘")
        for r in results["without_thought"]:
            print(f"Task: {r['task']}")
            print(f"Response: {r['response']}")
            print(f"Verifiable: {r['verifiable']}")
            print()
        
        print("\nã€æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ (ReAct)ã€‘")
        for r in results["with_thought"]:
            print(f"Task: {r['task']}")
            print(f"Response: {r['response']}")
            print(f"Verifiable: {r['verifiable']}")
            print()
        
        print("\nã€æ€»ç»“ã€‘")
        print("ä¼˜åŠ¿:")
        print("âœ“ å¯ä»¥éªŒè¯æ¯ä¸€æ­¥")
        print("âœ“ å¦‚æœå‡ºé”™ï¼Œèƒ½å¿«é€Ÿå®šä½")
        print("âœ“ ç”¨æˆ·èƒ½ç†è§£æ¨ç†è¿‡ç¨‹")
        print("âœ“ å®¹æ˜“å‘ç°å’Œä¿®å¤é—®é¢˜")

if __name__ == "__main__":
    exp = ReactExperiment()
    results = exp.compare_results()
    exp.print_analysis(results)
```

### âœ… ä»»åŠ¡æ£€æŸ¥æ¸…å•

- [ ] é˜…è¯» DEEP_LEARNING_PATH.md çš„ReActéƒ¨åˆ†
- [ ] ç†è§£Thought/Action/Observationçš„è®¾è®¡åŸç†
- [ ] å®Œæˆ week1_react_experiment.py
- [ ] èƒ½è§£é‡Šä¸ºä»€ä¹ˆReActæ›´æœ‰æ•ˆ
- [ ] æŒ‡å‡º1ä¸ªReActçš„ç¼ºç‚¹

---

## Week 1, Day 3-4: ä¸åŒé¢†åŸŸçš„Promptè®¾è®¡

### ä»»åŠ¡ï¼šä¸º4ä¸ªä¸åŒé¢†åŸŸè®¾è®¡Prompt

åˆ›å»ºæ–‡ä»¶ï¼š`week1_domain_prompts.py`

```python
# ä¸åŒé¢†åŸŸçš„Promptè®¾è®¡ç»ƒä¹ 

DOMAIN_PROMPTS = {
    "medical": """
# åŒ»å­¦è¯Šæ–­Prompt

ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦ä¿¡æ¯åŠ©æ‰‹ï¼ˆä¸æ˜¯åŒ»ç”Ÿï¼Œä¸æä¾›è¯Šæ–­ï¼‰

## æ ¸å¿ƒåŸåˆ™
âš ï¸ å§‹ç»ˆåœ¨æœ€åæé†’ç”¨æˆ·å’¨è¯¢åŒ»ç”Ÿ
âš ï¸ å¦‚æœä¸ç¡®å®šï¼Œè¯´"éœ€è¦å’¨è¯¢åŒ»ç”Ÿ"
âš ï¸ ç»™å‡ºç½®ä¿¡åº¦è¯„åˆ†

## å·¥å…·
1. symptom_database: æŸ¥è¯¢ç—‡çŠ¶
2. disease_list: æŸ¥è¯¢å¯èƒ½çš„ç–¾ç—…
3. treatment_guide: æŸ¥è¯¢æ²»ç–—æ–¹æ³•

## ReActæ¨¡å¼
Thought: [åˆ†æç—‡çŠ¶]
Action: [é€‰æ‹©å·¥å…·]
...
Final Answer: [å¯èƒ½çš„æƒ…å†µ + å¼ºçƒˆå»ºè®®å°±åŒ»]

## ç¤ºä¾‹
Input: "æˆ‘æœ‰å¤´ç—›å’Œå‘çƒ­"
Output:
Thought: ç”¨æˆ·æœ‰ä¸¤ä¸ªç—‡çŠ¶ï¼Œéœ€è¦æŸ¥è¯¢å¯èƒ½çš„ç–¾ç—…
Action: æŸ¥è¯¢ç—‡çŠ¶æ•°æ®åº“
...
Final Answer: 
å¯èƒ½çš„æƒ…å†µ:
- æ„Ÿå†’: 60% ç½®ä¿¡åº¦
- æµæ„Ÿ: 30% ç½®ä¿¡åº¦
âš ï¸ è¯·ç«‹å³å’¨è¯¢åŒ»ç”Ÿè¿›è¡Œæ­£å¼è¯Šæ–­
""",
    
    "financial": """
# è´¢åŠ¡æŠ•èµ„Prompt

ä½ æ˜¯ä¸€ä¸ªè´¢åŠ¡é¡¾é—®åŠ©æ‰‹

## æ ¸å¿ƒåŸåˆ™
âš ï¸ å§‹ç»ˆè¯´æ˜"è¿™ä¸æ˜¯æŠ•èµ„å»ºè®®"
âš ï¸ å¼ºè°ƒé£é™©ç®¡ç†
âš ï¸ å»ºè®®å¤šå…ƒåŒ–æŠ•èµ„
âš ï¸ è€ƒè™‘ä¸ªäººé£é™©æ‰¿å—èƒ½åŠ›

## å·¥å…·
1. market_data: è·å–å¸‚åœºæ•°æ®
2. asset_analysis: åˆ†æèµ„äº§
3. risk_calculator: è®¡ç®—é£é™©

## å…³é”®çº¦æŸ
- ä¸èƒ½ä¿è¯æ”¶ç›Š
- è¿‡å»è¡¨ç°ä¸é¢„ç¤ºæœªæ¥
- éœ€è¦å……åˆ†çš„é£é™©è®¤çŸ¥

## å·¥ä½œæµç¨‹
Thought: [ç†è§£ç”¨æˆ·æƒ…å†µ]
Action: [æŸ¥è¯¢å¸‚åœºæ•°æ®]
Observation: [åˆ†ææ•°æ®]
...
Final Answer: [å¤šä¸ªé€‰é¡¹ + é£é™©è¯´æ˜]
""",
    
    "code_review": """
# ä»£ç å®¡æŸ¥Prompt

ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ä»£ç å®¡æŸ¥äººå‘˜

## å®¡æŸ¥ç»´åº¦
1. æ­£ç¡®æ€§: ä»£ç æ˜¯å¦æ­£ç¡®ï¼Ÿ
2. æ€§èƒ½: æ˜¯å¦æœ‰æ€§èƒ½é—®é¢˜ï¼Ÿ
3. å¯è¯»æ€§: ä»£ç æ¸…æ¥šå—ï¼Ÿ
4. å®‰å…¨æ€§: æœ‰å®‰å…¨é—®é¢˜å—ï¼Ÿ
5. æœ€ä½³å®è·µ: éµå¾ªæ ‡å‡†å—ï¼Ÿ

## å·¥å…·
1. analyze_code: åˆ†æä»£ç 
2. suggest_fix: æä¾›ä¿®å¤å»ºè®®
3. check_best_practice: æ£€æŸ¥æœ€ä½³å®è·µ

## åé¦ˆé£æ ¼
- å…ˆè¡¨æ‰¬å¥½çš„åœ°æ–¹
- ç„¶åæŒ‡å‡ºé—®é¢˜
- æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®
- ç»™å‡ºä»£ç ç¤ºä¾‹

## å·¥ä½œæµç¨‹
Thought: [ç†è§£ä»£ç çš„ç›®çš„]
Action: [æŒ‰ç»´åº¦åˆ†æ]
Observation: [å‘ç°é—®é¢˜]
...
Final Answer: [æ±‡æ€»æŠ¥å‘Š + ä¼˜å…ˆçº§]
""",
    
    "research": """
# å­¦æœ¯ç ”ç©¶Prompt

ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹

## å·¥å…·
1. search_papers: æœç´¢ç›¸å…³è®ºæ–‡
2. summarize_paper: æ€»ç»“è®ºæ–‡
3. compare_methods: æ¯”è¾ƒæ–¹æ³•

## åˆ†ææ¡†æ¶
1. ç ”ç©¶é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ
2. è§£å†³æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ
3. å®éªŒç»“æœå¦‚ä½•ï¼Ÿ
4. æœ‰ä»€ä¹ˆé™åˆ¶ï¼Ÿ
5. æœªæ¥å·¥ä½œæ–¹å‘ï¼Ÿ

## å­¦æœ¯ä¸¥è°¨æ€§
- å¼•ç”¨åŸæ–‡å’Œä½œè€…
- åŒºåˆ†äº‹å®å’Œè§£é‡Š
- æ‰¿è®¤ä¸ç¡®å®šæ€§
- è€ƒè™‘åé©³

## å·¥ä½œæµç¨‹
Thought: [ç†è§£ç ”ç©¶é—®é¢˜]
Action: [æœç´¢ç›¸å…³è®ºæ–‡]
Observation: [åˆ†æå‘ç°]
...
Final Answer: [å­¦æœ¯æ€»ç»“ + åŸå§‹è®ºæ–‡å¼•ç”¨]
"""
}

# ç»ƒä¹ ï¼šä¸ºæ¯ä¸ªPromptè¯„åˆ†
class PromptEvaluator:
    """Promptè¯„ä¼°å™¨"""
    
    @staticmethod
    def evaluate_prompt(prompt: str) -> dict:
        """è¯„ä¼°Promptçš„è´¨é‡"""
        scores = {
            "clarity": 0,      # æ¸…æ™°åº¦
            "completeness": 0, # å®Œæ•´æ€§
            "constraints": 0,  # çº¦æŸæ¸…æ™°åº¦
            "examples": 0,     # ç¤ºä¾‹å……åˆ†æ€§
            "safety": 0        # å®‰å…¨æ€§
        }
        
        # æ£€æŸ¥å„é¡¹æŒ‡æ ‡
        if "ReAct" in prompt or "Thought" in prompt:
            scores["clarity"] += 2
        
        if len(prompt) > 500:
            scores["completeness"] += 2
        
        if "çº¦æŸ" in prompt or "ä¸èƒ½" in prompt:
            scores["constraints"] += 2
        
        if "ç¤ºä¾‹" in prompt:
            scores["examples"] += 2
        
        if "âš ï¸" in prompt or "å®‰å…¨" in prompt:
            scores["safety"] += 2
        
        return scores
    
    @staticmethod
    def print_evaluation(domain: str, scores: dict):
        """æ‰“å°è¯„ä¼°"""
        print(f"\nã€{domain} Prompt è¯„ä¼°ã€‘")
        total = sum(scores.values())
        for key, value in scores.items():
            bar = "â–ˆ" * value + "â–‘" * (10 - value)
            print(f"{key:15} {bar} {value}/10")
        print(f"{'æ€»åˆ†':15} {total}/50")

if __name__ == "__main__":
    evaluator = PromptEvaluator()
    
    for domain, prompt in DOMAIN_PROMPTS.items():
        scores = evaluator.evaluate_prompt(prompt)
        evaluator.print_evaluation(domain, scores)
    
    # é€‰æ‹©ä¸€ä¸ªPromptï¼Œå†™å‡ºæ”¹è¿›ç‰ˆæœ¬
    print("\n" + "="*60)
    print("æ”¹è¿›ç»ƒä¹ ï¼šé€‰æ‹©ä¸€ä¸ªPromptå¹¶æ”¹è¿›å®ƒ")
    print("="*60)
    print("""
å»ºè®®æ”¹è¿›ç‚¹:
1. æ·»åŠ æ›´å¤šå…·ä½“çš„çº¦æŸ
2. æä¾›æ›´å¤šä½¿ç”¨ç¤ºä¾‹
3. æ˜ç¡®è¯´æ˜å¤±è´¥å¤„ç†
4. æ·»åŠ å®‰å…¨è­¦å‘Š
""")
```

### âœ… ä»»åŠ¡æ£€æŸ¥æ¸…å•

- [ ] ç†è§£æ¯ä¸ªé¢†åŸŸçš„ç‰¹æ®Šéœ€æ±‚
- [ ] å®Œæˆ4ä¸ªPromptçš„è®¾è®¡
- [ ] æ¯ä¸ªPromptéƒ½åŒ…å«ReActæ¡†æ¶
- [ ] è€ƒè™‘äº†é¢†åŸŸç‰¹å®šçš„é£é™©
- [ ] æ·»åŠ äº†é€‚å½“çš„çº¦æŸ

---

## Week 1, Day 5-7: Promptæ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯•

### ä»»åŠ¡ï¼šä¼˜åŒ–å¹¶æµ‹è¯•Prompt

åˆ›å»ºæ–‡ä»¶ï¼š`week1_prompt_optimization.py`

```python
# Promptä¼˜åŒ–å’Œæ€§èƒ½æµ‹è¯•

class PromptOptimizationWorkshop:
    """Promptä¼˜åŒ–å·¥ä½œåŠ"""
    
    def __init__(self):
        self.test_cases = [
            {"input": "è®¡ç®— 10+5", "category": "simple_math"},
            {"input": "è®¡ç®— (20+30)*2-10", "category": "complex_math"},
            {"input": "æŸ¥è¯¢Pythonå®šä¹‰", "category": "definition"},
        ]
    
    def test_prompt_version(self, prompt: str, version_name: str) -> dict:
        """æµ‹è¯•Promptçš„ä¸€ä¸ªç‰ˆæœ¬"""
        results = {
            "version": version_name,
            "test_results": [],
            "stats": {
                "passed": 0,
                "failed": 0,
                "avg_clarity": 0,
                "avg_completeness": 0
            }
        }
        
        for test in self.test_cases:
            # æ¨¡æ‹ŸLLMè°ƒç”¨
            response = self._simulate_llm(prompt, test["input"])
            
            # è¯„ä¼°å“åº”
            evaluation = self._evaluate_response(response, test)
            
            results["test_results"].append({
                "input": test["input"],
                "category": test["category"],
                **evaluation
            })
            
            if evaluation["clarity_score"] > 7:
                results["stats"]["passed"] += 1
            else:
                results["stats"]["failed"] += 1
        
        # è®¡ç®—å¹³å‡å€¼
        results["stats"]["avg_clarity"] = sum(
            r["clarity_score"] for r in results["test_results"]
        ) / len(results["test_results"])
        
        return results
    
    def _simulate_llm(self, prompt: str, input_text: str) -> str:
        """æ¨¡æ‹ŸLLMè°ƒç”¨"""
        # åœ¨å®é™…åº”ç”¨ä¸­è¿™é‡Œä¼šè°ƒç”¨çœŸå®LLM
        return f"Response to: {input_text}"
    
    def _evaluate_response(self, response: str, test: dict) -> dict:
        """è¯„ä¼°å“åº”è´¨é‡"""
        return {
            "clarity_score": 7,  # 0-10
            "completeness_score": 8,  # 0-10
            "follows_format": "Thought" in response
        }
    
    def compare_versions(self):
        """å¯¹æ¯”ä¸åŒç‰ˆæœ¬"""
        versions = [
            ("åŸºç¡€ç‰ˆæœ¬", "è¯·å›ç­”è¿™ä¸ªé—®é¢˜: {query}"),
            ("ReActç‰ˆæœ¬", "è¯·æŒ‰ç…§Thought->Action->Observationçš„æ–¹å¼..."),
            ("æ”¹è¿›ç‰ˆæœ¬", "è¯¦ç»†çš„Prompt...")
        ]
        
        results = []
        for name, prompt in versions:
            result = self.test_prompt_version(prompt, name)
            results.append(result)
        
        return results
    
    def print_comparison_report(self, results):
        """æ‰“å°å¯¹æ¯”æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("Promptç‰ˆæœ¬å¯¹æ¯”æŠ¥å‘Š")
        print("="*60)
        
        for result in results:
            print(f"\nã€{result['version']}ã€‘")
            print(f"æˆåŠŸ: {result['stats']['passed']}")
            print(f"å¤±è´¥: {result['stats']['failed']}")
            print(f"å¹³å‡æ¸…æ™°åº¦: {result['stats']['avg_clarity']:.1f}/10")

if __name__ == "__main__":
    workshop = PromptOptimizationWorkshop()
    results = workshop.compare_versions()
    workshop.print_comparison_report(results)
```

### âœ… ç¬¬ä¸€å‘¨æ€»ç»“æ£€æŸ¥

- [ ] å®Œæˆ3ä¸ªä»£ç æ–‡ä»¶çš„å®ç°
- [ ] ç†è§£äº†ReActçš„è®¾è®¡åŸç†
- [ ] èƒ½ä¸ºä¸åŒé¢†åŸŸè®¾è®¡Prompt
- [ ] ç†è§£äº†Promptä¼˜åŒ–çš„è¿‡ç¨‹
- [ ] èƒ½è¯„ä¼°Promptçš„è´¨é‡

---

## ç°åœ¨å°±å¼€å§‹ï¼

1. **é˜…è¯»** `DEEP_LEARNING_PATH.md` çš„ç¬¬ä¸€å‘¨éƒ¨åˆ†
2. **åˆ›å»º** `week1_react_analysis.md` å¹¶è®°å½•ä½ çš„ç†è§£
3. **å®ç°** `week1_react_experiment.py`
4. **è®¾è®¡** 4ä¸ªé¢†åŸŸçš„Prompt
5. **æµ‹è¯•** å’Œä¼˜åŒ–ä½ çš„Prompt

**é¢„æœŸæˆæœ**ï¼š
- âœ… ç†è§£ReActèŒƒå¼çš„ç²¾é«“
- âœ… èƒ½ä¸ºç‰¹å®šé¢†åŸŸè®¾è®¡é«˜è´¨é‡Prompt
- âœ… ç†è§£Promptä¼˜åŒ–çš„æ–¹æ³•è®º

**ä¸‹ä¸€å‘¨è®¡åˆ’**ï¼šå®ç°é«˜çº§Agentç³»ç»Ÿ

---

å‡†å¤‡å¥½äº†å—ï¼Ÿ ğŸš€
